This repository archives all screenshots from the experimental phase of the study "The Exploitation of Large Language Models by Malicious Actors: Emerging Risks to Border Security through Natural Language Processing." It contains visual evidence from interactions with publicly accessible LLMs (ChatGPT-4.5/4o, Claude Sonnet 3.7, Gemini 2.5 Flash, Grok, and Runway ML Gen-2) across ten distinct adversarial scenarios. Each folder corresponds to a specific risk category (e.g., Fake News Generation, Document Forgery, Social Engineering), showcasing model outputs in response to obfuscated or benign-framed prompts. This dataset ensures transparency, reproducibility, and external auditability of the findings reported in the paper.
